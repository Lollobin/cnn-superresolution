{"cells":[{"cell_type":"markdown","metadata":{"id":"IABybSFt_Abf"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111703,"status":"ok","timestamp":1728397170072,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"OTR8hWUC-SX0","outputId":"34068e2d-6d7f-4dc9-da87-cb5cc6c1f886"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ux8qA-hA-Ud8","outputId":"c5761a5d-05e9-4872-a014-335d9ed734ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/GitHub/dl-superresolution-ipynb\n"]}],"source":["working_directory = 'GitHub/dl-superresolution-ipynb'\n","%cd /content/drive/MyDrive/$working_directory\n","!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18342,"status":"ok","timestamp":1728388695293,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"dObxHyJH_f-Q","outputId":"0e6f4310-dcfe-4c81-fd63-e56b9cc943b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting patchify==0.2.3 (from -r requirements.txt (line 1))\n","  Downloading patchify-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n","Collecting matplotlib==3.9.2 (from -r requirements.txt (line 2))\n","  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: tqdm==4.66.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.5)\n","Requirement already satisfied: opencv-python==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.10.0.84)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify==0.2.3->-r requirements.txt (line 1)) (1.26.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (24.1)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.9.2->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.2->-r requirements.txt (line 2)) (1.16.0)\n","Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n","Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: patchify, matplotlib\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.7.1\n","    Uninstalling matplotlib-3.7.1:\n","      Successfully uninstalled matplotlib-3.7.1\n","Successfully installed matplotlib-3.9.2 patchify-0.2.3\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"0_sC6ggR_suO"},"source":["## Git Management"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8EldXDCAATXb"},"outputs":[],"source":["!git config --global user.email \"e11909390@student.tuwien.ac.at\"\n","!git config --global user.name \"Lollobin\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11703,"status":"ok","timestamp":1728388290213,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"Oh3n9PMjBby0","outputId":"3a916314-3a9c-4e19-f7d9-3d16f79a85b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["remote: Enumerating objects: 203, done.\u001b[K\n","remote: Counting objects:   0% (1/203)\u001b[K\rremote: Counting objects:   1% (3/203)\u001b[K\rremote: Counting objects:   2% (5/203)\u001b[K\rremote: Counting objects:   3% (7/203)\u001b[K\rremote: Counting objects:   4% (9/203)\u001b[K\rremote: Counting objects:   5% (11/203)\u001b[K\rremote: Counting objects:   6% (13/203)\u001b[K\rremote: Counting objects:   7% (15/203)\u001b[K\rremote: Counting objects:   8% (17/203)\u001b[K\rremote: Counting objects:   9% (19/203)\u001b[K\rremote: Counting objects:  10% (21/203)\u001b[K\rremote: Counting objects:  11% (23/203)\u001b[K\rremote: Counting objects:  12% (25/203)\u001b[K\rremote: Counting objects:  13% (27/203)\u001b[K\rremote: Counting objects:  14% (29/203)\u001b[K\rremote: Counting objects:  15% (31/203)\u001b[K\rremote: Counting objects:  16% (33/203)\u001b[K\rremote: Counting objects:  17% (35/203)\u001b[K\rremote: Counting objects:  18% (37/203)\u001b[K\rremote: Counting objects:  19% (39/203)\u001b[K\rremote: Counting objects:  20% (41/203)\u001b[K\rremote: Counting objects:  21% (43/203)\u001b[K\rremote: Counting objects:  22% (45/203)\u001b[K\rremote: Counting objects:  23% (47/203)\u001b[K\rremote: Counting objects:  24% (49/203)\u001b[K\rremote: Counting objects:  25% (51/203)\u001b[K\rremote: Counting objects:  26% (53/203)\u001b[K\rremote: Counting objects:  27% (55/203)\u001b[K\rremote: Counting objects:  28% (57/203)\u001b[K\rremote: Counting objects:  29% (59/203)\u001b[K\rremote: Counting objects:  30% (61/203)\u001b[K\rremote: Counting objects:  31% (63/203)\u001b[K\rremote: Counting objects:  32% (65/203)\u001b[K\rremote: Counting objects:  33% (67/203)\u001b[K\rremote: Counting objects:  34% (70/203)\u001b[K\rremote: Counting objects:  35% (72/203)\u001b[K\rremote: Counting objects:  36% (74/203)\u001b[K\rremote: Counting objects:  37% (76/203)\u001b[K\rremote: Counting objects:  38% (78/203)\u001b[K\rremote: Counting objects:  39% (80/203)\u001b[K\rremote: Counting objects:  40% (82/203)\u001b[K\rremote: Counting objects:  41% (84/203)\u001b[K\rremote: Counting objects:  42% (86/203)\u001b[K\rremote: Counting objects:  43% (88/203)\u001b[K\rremote: Counting objects:  44% (90/203)\u001b[K\rremote: Counting objects:  45% (92/203)\u001b[K\rremote: Counting objects:  46% (94/203)\u001b[K\rremote: Counting objects:  47% (96/203)\u001b[K\rremote: Counting objects:  48% (98/203)\u001b[K\rremote: Counting objects:  49% (100/203)\u001b[K\rremote: Counting objects:  50% (102/203)\u001b[K\rremote: Counting objects:  51% (104/203)\u001b[K\rremote: Counting objects:  52% (106/203)\u001b[K\rremote: Counting objects:  53% (108/203)\u001b[K\rremote: Counting objects:  54% (110/203)\u001b[K\rremote: Counting objects:  55% (112/203)\u001b[K\rremote: Counting objects:  56% (114/203)\u001b[K\rremote: Counting objects:  57% (116/203)\u001b[K\rremote: Counting objects:  58% (118/203)\u001b[K\rremote: Counting objects:  59% (120/203)\u001b[K\rremote: Counting objects:  60% (122/203)\u001b[K\rremote: Counting objects:  61% (124/203)\u001b[K\rremote: Counting objects:  62% (126/203)\u001b[K\rremote: Counting objects:  63% (128/203)\u001b[K\rremote: Counting objects:  64% (130/203)\u001b[K\rremote: Counting objects:  65% (132/203)\u001b[K\rremote: Counting objects:  66% (134/203)\u001b[K\rremote: Counting objects:  67% (137/203)\u001b[K\rremote: Counting objects:  68% (139/203)\u001b[K\rremote: Counting objects:  69% (141/203)\u001b[K\rremote: Counting objects:  70% (143/203)\u001b[K\rremote: Counting objects:  71% (145/203)\u001b[K\rremote: Counting objects:  72% (147/203)\u001b[K\rremote: Counting objects:  73% (149/203)\u001b[K\rremote: Counting objects:  74% (151/203)\u001b[K\rremote: Counting objects:  75% (153/203)\u001b[K\rremote: Counting objects:  76% (155/203)\u001b[K\rremote: Counting objects:  77% (157/203)\u001b[K\rremote: Counting objects:  78% (159/203)\u001b[K\rremote: Counting objects:  79% (161/203)\u001b[K\rremote: Counting objects:  80% (163/203)\u001b[K\rremote: Counting objects:  81% (165/203)\u001b[K\rremote: Counting objects:  82% (167/203)\u001b[K\rremote: Counting objects:  83% (169/203)\u001b[K\rremote: Counting objects:  84% (171/203)\u001b[K\rremote: Counting objects:  85% (173/203)\u001b[K\rremote: Counting objects:  86% (175/203)\u001b[K\rremote: Counting objects:  87% (177/203)\u001b[K\rremote: Counting objects:  88% (179/203)\u001b[K\rremote: Counting objects:  89% (181/203)\u001b[K\rremote: Counting objects:  90% (183/203)\u001b[K\rremote: Counting objects:  91% (185/203)\u001b[K\rremote: Counting objects:  92% (187/203)\u001b[K\rremote: Counting objects:  93% (189/203)\u001b[K\rremote: Counting objects:  94% (191/203)\u001b[K\rremote: Counting objects:  95% (193/203)\u001b[K\rremote: Counting objects:  96% (195/203)\u001b[K\rremote: Counting objects:  97% (197/203)\u001b[K\rremote: Counting objects:  98% (199/203)\u001b[K\rremote: Counting objects:  99% (201/203)\u001b[K\rremote: Counting objects: 100% (203/203)\u001b[K\rremote: Counting objects: 100% (203/203), done.\u001b[K\n","remote: Compressing objects: 100% (196/196), done.\u001b[K\n","remote: Total 202 (delta 6), reused 202 (delta 6), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (202/202), 21.93 MiB | 13.67 MiB/s, done.\n","Resolving deltas: 100% (6/6), completed with 1 local object.\n","From https://github.com/Lollobin/dl-superresolution-ipynb\n","   1a17ac2..2897d9e  main       -> origin/main\n","Updating 1a17ac2..2897d9e\n","Updating files: 100% (186/186), done.\n","Fast-forward\n"," input/Set14/GTmod12/baboon.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m523337\u001b[m bytes\n"," input/Set14/GTmod12/barbara.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m821015\u001b[m bytes\n"," input/Set14/GTmod12/bridge.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m275872\u001b[m bytes\n"," input/Set14/GTmod12/coastguard.png  | Bin \u001b[31m0\u001b[m -> \u001b[32m152880\u001b[m bytes\n"," input/Set14/GTmod12/comic.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m184796\u001b[m bytes\n"," input/Set14/GTmod12/face.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m110826\u001b[m bytes\n"," input/Set14/GTmod12/flowers.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m341974\u001b[m bytes\n"," input/Set14/GTmod12/foreman.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m128602\u001b[m bytes\n"," input/Set14/GTmod12/lenna.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m364183\u001b[m bytes\n"," input/Set14/GTmod12/man.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m308821\u001b[m bytes\n"," input/Set14/GTmod12/monarch.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m609770\u001b[m bytes\n"," input/Set14/GTmod12/pepper.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m491778\u001b[m bytes\n"," input/Set14/GTmod12/ppt3.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m269062\u001b[m bytes\n"," input/Set14/GTmod12/zebra.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m427737\u001b[m bytes\n"," input/Set14/LRbicx2/baboon.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m135000\u001b[m bytes\n"," input/Set14/LRbicx2/barbara.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m205344\u001b[m bytes\n"," input/Set14/LRbicx2/bridge.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m81181\u001b[m bytes\n"," input/Set14/LRbicx2/coastguard.png  | Bin \u001b[31m0\u001b[m -> \u001b[32m43669\u001b[m bytes\n"," input/Set14/LRbicx2/comic.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m51076\u001b[m bytes\n"," input/Set14/LRbicx2/face.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m32163\u001b[m bytes\n"," input/Set14/LRbicx2/flowers.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m90552\u001b[m bytes\n"," input/Set14/LRbicx2/foreman.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m40966\u001b[m bytes\n"," input/Set14/LRbicx2/lenna.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m113067\u001b[m bytes\n"," input/Set14/LRbicx2/man.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m78351\u001b[m bytes\n"," input/Set14/LRbicx2/monarch.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m166148\u001b[m bytes\n"," input/Set14/LRbicx2/pepper.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m110149\u001b[m bytes\n"," input/Set14/LRbicx2/ppt3.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m83947\u001b[m bytes\n"," input/Set14/LRbicx2/zebra.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m121765\u001b[m bytes\n"," input/Set14/LRbicx3/baboon.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m59650\u001b[m bytes\n"," input/Set14/LRbicx3/barbara.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m90943\u001b[m bytes\n"," input/Set14/LRbicx3/bridge.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m37875\u001b[m bytes\n"," input/Set14/LRbicx3/coastguard.png  | Bin \u001b[31m0\u001b[m -> \u001b[32m19591\u001b[m bytes\n"," input/Set14/LRbicx3/comic.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m23719\u001b[m bytes\n"," input/Set14/LRbicx3/face.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m15015\u001b[m bytes\n"," input/Set14/LRbicx3/flowers.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m42246\u001b[m bytes\n"," input/Set14/LRbicx3/foreman.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m20729\u001b[m bytes\n"," input/Set14/LRbicx3/lenna.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m51517\u001b[m bytes\n"," input/Set14/LRbicx3/man.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m37415\u001b[m bytes\n"," input/Set14/LRbicx3/monarch.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m79575\u001b[m bytes\n"," input/Set14/LRbicx3/pepper.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m51673\u001b[m bytes\n"," input/Set14/LRbicx3/ppt3.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m42881\u001b[m bytes\n"," input/Set14/LRbicx3/zebra.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m57176\u001b[m bytes\n"," input/Set14/LRbicx4/baboon.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m33404\u001b[m bytes\n"," input/Set14/LRbicx4/barbara.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m51740\u001b[m bytes\n"," input/Set14/LRbicx4/bridge.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m22303\u001b[m bytes\n"," input/Set14/LRbicx4/coastguard.png  | Bin \u001b[31m0\u001b[m -> \u001b[32m11061\u001b[m bytes\n"," input/Set14/LRbicx4/comic.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m13622\u001b[m bytes\n"," input/Set14/LRbicx4/face.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m8825\u001b[m bytes\n"," input/Set14/LRbicx4/flowers.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m24556\u001b[m bytes\n"," input/Set14/LRbicx4/foreman.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m12609\u001b[m bytes\n"," input/Set14/LRbicx4/lenna.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m29816\u001b[m bytes\n"," input/Set14/LRbicx4/man.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m22505\u001b[m bytes\n"," input/Set14/LRbicx4/monarch.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m47304\u001b[m bytes\n"," input/Set14/LRbicx4/pepper.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m30627\u001b[m bytes\n"," input/Set14/LRbicx4/ppt3.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m26684\u001b[m bytes\n"," input/Set14/LRbicx4/zebra.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m33172\u001b[m bytes\n"," input/Set14/original/baboon.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m531037\u001b[m bytes\n"," input/Set14/original/barbara.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m821015\u001b[m bytes\n"," input/Set14/original/bridge.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m283024\u001b[m bytes\n"," input/Set14/original/coastguard.png | Bin \u001b[31m0\u001b[m -> \u001b[32m154469\u001b[m bytes\n"," input/Set14/original/comic.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m192855\u001b[m bytes\n"," input/Set14/original/face.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m110826\u001b[m bytes\n"," input/Set14/original/flowers.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m348592\u001b[m bytes\n"," input/Set14/original/foreman.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m130720\u001b[m bytes\n"," input/Set14/original/lenna.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m374782\u001b[m bytes\n"," input/Set14/original/man.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m318631\u001b[m bytes\n"," input/Set14/original/monarch.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m618686\u001b[m bytes\n"," input/Set14/original/pepper.png     | Bin \u001b[31m0\u001b[m -> \u001b[32m507582\u001b[m bytes\n"," input/Set14/original/ppt3.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m269159\u001b[m bytes\n"," input/Set14/original/zebra.png      | Bin \u001b[31m0\u001b[m -> \u001b[32m442990\u001b[m bytes\n"," input/Set5/GTmod12/baby.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m363396\u001b[m bytes\n"," input/Set5/GTmod12/bird.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m120453\u001b[m bytes\n"," input/Set5/GTmod12/butterfly.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m123648\u001b[m bytes\n"," input/Set5/GTmod12/head.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m110087\u001b[m bytes\n"," input/Set5/GTmod12/woman.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m116180\u001b[m bytes\n"," input/Set5/LRbicx2/baby.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m107013\u001b[m bytes\n"," input/Set5/LRbicx2/bird.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m38322\u001b[m bytes\n"," input/Set5/LRbicx2/butterfly.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m34843\u001b[m bytes\n"," input/Set5/LRbicx2/head.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m32093\u001b[m bytes\n"," input/Set5/LRbicx2/woman.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m35857\u001b[m bytes\n"," input/Set5/LRbicx3/baby.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m51276\u001b[m bytes\n"," input/Set5/LRbicx3/bird.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m18838\u001b[m bytes\n"," input/Set5/LRbicx3/butterfly.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m16934\u001b[m bytes\n"," input/Set5/LRbicx3/head.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m15014\u001b[m bytes\n"," input/Set5/LRbicx3/woman.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m17598\u001b[m bytes\n"," input/Set5/LRbicx4/baby.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m30380\u001b[m bytes\n"," input/Set5/LRbicx4/bird.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m11288\u001b[m bytes\n"," input/Set5/LRbicx4/butterfly.png    | Bin \u001b[31m0\u001b[m -> \u001b[32m10089\u001b[m bytes\n"," input/Set5/LRbicx4/head.png         | Bin \u001b[31m0\u001b[m -> \u001b[32m8815\u001b[m bytes\n"," input/Set5/LRbicx4/woman.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m10585\u001b[m bytes\n"," input/Set5/original/baby.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m371264\u001b[m bytes\n"," input/Set5/original/bird.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m120453\u001b[m bytes\n"," input/Set5/original/butterfly.png   | Bin \u001b[31m0\u001b[m -> \u001b[32m127529\u001b[m bytes\n"," input/Set5/original/head.png        | Bin \u001b[31m0\u001b[m -> \u001b[32m113787\u001b[m bytes\n"," input/Set5/original/woman.png       | Bin \u001b[31m0\u001b[m -> \u001b[32m118848\u001b[m bytes\n"," input/T91/t1.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m66074\u001b[m bytes\n"," input/T91/t10.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m46749\u001b[m bytes\n"," input/T91/t11.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m89058\u001b[m bytes\n"," input/T91/t12.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m25215\u001b[m bytes\n"," input/T91/t13.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m58662\u001b[m bytes\n"," input/T91/t14.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m35574\u001b[m bytes\n"," input/T91/t15.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m76607\u001b[m bytes\n"," input/T91/t16.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m46757\u001b[m bytes\n"," input/T91/t17.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m48484\u001b[m bytes\n"," input/T91/t18.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m39145\u001b[m bytes\n"," input/T91/t19.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m61462\u001b[m bytes\n"," input/T91/t2.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m53516\u001b[m bytes\n"," input/T91/t20.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m12557\u001b[m bytes\n"," input/T91/t21.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m23717\u001b[m bytes\n"," input/T91/t22.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m31978\u001b[m bytes\n"," input/T91/t23.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m23622\u001b[m bytes\n"," input/T91/t24.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m22006\u001b[m bytes\n"," input/T91/t25.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m65776\u001b[m bytes\n"," input/T91/t26.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m35480\u001b[m bytes\n"," input/T91/t27.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m93312\u001b[m bytes\n"," input/T91/t28.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m58736\u001b[m bytes\n"," input/T91/t29.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m68514\u001b[m bytes\n"," input/T91/t3.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m45547\u001b[m bytes\n"," input/T91/t30.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m39873\u001b[m bytes\n"," input/T91/t31.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m64959\u001b[m bytes\n"," input/T91/t32.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m52636\u001b[m bytes\n"," input/T91/t33.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m51126\u001b[m bytes\n"," input/T91/t34.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m36418\u001b[m bytes\n"," input/T91/t35.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m84308\u001b[m bytes\n"," input/T91/t36.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m83578\u001b[m bytes\n"," input/T91/t37.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m212727\u001b[m bytes\n"," input/T91/t38.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m81870\u001b[m bytes\n"," input/T91/t39.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m96889\u001b[m bytes\n"," input/T91/t4.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m87585\u001b[m bytes\n"," input/T91/t40.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m128649\u001b[m bytes\n"," input/T91/t42.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m105422\u001b[m bytes\n"," input/T91/t43.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m83272\u001b[m bytes\n"," input/T91/t44.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m58615\u001b[m bytes\n"," input/T91/t45.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m91890\u001b[m bytes\n"," input/T91/t46.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m210095\u001b[m bytes\n"," input/T91/t47.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m81039\u001b[m bytes\n"," input/T91/t48.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m69963\u001b[m bytes\n"," input/T91/t49.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m112914\u001b[m bytes\n"," input/T91/t5.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m38351\u001b[m bytes\n"," input/T91/t50.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m171990\u001b[m bytes\n"," input/T91/t51.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m192270\u001b[m bytes\n"," input/T91/t52.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m95433\u001b[m bytes\n"," input/T91/t53.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m116367\u001b[m bytes\n"," input/T91/t54.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m60873\u001b[m bytes\n"," input/T91/t55.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m48621\u001b[m bytes\n"," input/T91/t56.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m53500\u001b[m bytes\n"," input/T91/t57.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m65274\u001b[m bytes\n"," input/T91/t58.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m53951\u001b[m bytes\n"," input/T91/t59.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m126166\u001b[m bytes\n"," input/T91/t6.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m60159\u001b[m bytes\n"," input/T91/t60.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m89319\u001b[m bytes\n"," input/T91/t61.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m53329\u001b[m bytes\n"," input/T91/t62.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m81483\u001b[m bytes\n"," input/T91/t63.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m63284\u001b[m bytes\n"," input/T91/t64.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m86845\u001b[m bytes\n"," input/T91/t65.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m83578\u001b[m bytes\n"," input/T91/t66.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m111721\u001b[m bytes\n"," input/T91/t7.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m51283\u001b[m bytes\n"," input/T91/t8.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m84197\u001b[m bytes\n"," input/T91/t9.png                    | Bin \u001b[31m0\u001b[m -> \u001b[32m25424\u001b[m bytes\n"," input/T91/tt1.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m216186\u001b[m bytes\n"," input/T91/tt10.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m204687\u001b[m bytes\n"," input/T91/tt12.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m211528\u001b[m bytes\n"," input/T91/tt13.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m232773\u001b[m bytes\n"," input/T91/tt14.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m93679\u001b[m bytes\n"," input/T91/tt15.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m150815\u001b[m bytes\n"," input/T91/tt16.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m100523\u001b[m bytes\n"," input/T91/tt17.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m129415\u001b[m bytes\n"," input/T91/tt18.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m59529\u001b[m bytes\n"," input/T91/tt19.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m109681\u001b[m bytes\n"," input/T91/tt2.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m252667\u001b[m bytes\n"," input/T91/tt20.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m168716\u001b[m bytes\n"," input/T91/tt21.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m227734\u001b[m bytes\n"," input/T91/tt22.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m105608\u001b[m bytes\n"," input/T91/tt23.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m207422\u001b[m bytes\n"," input/T91/tt24.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m191817\u001b[m bytes\n"," input/T91/tt25.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m240109\u001b[m bytes\n"," input/T91/tt26.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m226405\u001b[m bytes\n"," input/T91/tt27.png                  | Bin \u001b[31m0\u001b[m -> \u001b[32m156925\u001b[m bytes\n"," input/T91/tt3.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m270102\u001b[m bytes\n"," input/T91/tt4.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m243083\u001b[m bytes\n"," input/T91/tt5.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m264966\u001b[m bytes\n"," input/T91/tt6.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m278504\u001b[m bytes\n"," input/T91/tt7.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m97435\u001b[m bytes\n"," input/T91/tt8.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m202195\u001b[m bytes\n"," input/T91/tt9.png                   | Bin \u001b[31m0\u001b[m -> \u001b[32m251455\u001b[m bytes\n"," 186 files changed, 0 insertions(+), 0 deletions(-)\n"," create mode 100644 input/Set14/GTmod12/baboon.png\n"," create mode 100644 input/Set14/GTmod12/barbara.png\n"," create mode 100644 input/Set14/GTmod12/bridge.png\n"," create mode 100644 input/Set14/GTmod12/coastguard.png\n"," create mode 100644 input/Set14/GTmod12/comic.png\n"," create mode 100644 input/Set14/GTmod12/face.png\n"," create mode 100644 input/Set14/GTmod12/flowers.png\n"," create mode 100644 input/Set14/GTmod12/foreman.png\n"," create mode 100644 input/Set14/GTmod12/lenna.png\n"," create mode 100644 input/Set14/GTmod12/man.png\n"," create mode 100644 input/Set14/GTmod12/monarch.png\n"," create mode 100644 input/Set14/GTmod12/pepper.png\n"," create mode 100644 input/Set14/GTmod12/ppt3.png\n"," create mode 100644 input/Set14/GTmod12/zebra.png\n"," create mode 100644 input/Set14/LRbicx2/baboon.png\n"," create mode 100644 input/Set14/LRbicx2/barbara.png\n"," create mode 100644 input/Set14/LRbicx2/bridge.png\n"," create mode 100644 input/Set14/LRbicx2/coastguard.png\n"," create mode 100644 input/Set14/LRbicx2/comic.png\n"," create mode 100644 input/Set14/LRbicx2/face.png\n"," create mode 100644 input/Set14/LRbicx2/flowers.png\n"," create mode 100644 input/Set14/LRbicx2/foreman.png\n"," create mode 100644 input/Set14/LRbicx2/lenna.png\n"," create mode 100644 input/Set14/LRbicx2/man.png\n"," create mode 100644 input/Set14/LRbicx2/monarch.png\n"," create mode 100644 input/Set14/LRbicx2/pepper.png\n"," create mode 100644 input/Set14/LRbicx2/ppt3.png\n"," create mode 100644 input/Set14/LRbicx2/zebra.png\n"," create mode 100644 input/Set14/LRbicx3/baboon.png\n"," create mode 100644 input/Set14/LRbicx3/barbara.png\n"," create mode 100644 input/Set14/LRbicx3/bridge.png\n"," create mode 100644 input/Set14/LRbicx3/coastguard.png\n"," create mode 100644 input/Set14/LRbicx3/comic.png\n"," create mode 100644 input/Set14/LRbicx3/face.png\n"," create mode 100644 input/Set14/LRbicx3/flowers.png\n"," create mode 100644 input/Set14/LRbicx3/foreman.png\n"," create mode 100644 input/Set14/LRbicx3/lenna.png\n"," create mode 100644 input/Set14/LRbicx3/man.png\n"," create mode 100644 input/Set14/LRbicx3/monarch.png\n"," create mode 100644 input/Set14/LRbicx3/pepper.png\n"," create mode 100644 input/Set14/LRbicx3/ppt3.png\n"," create mode 100644 input/Set14/LRbicx3/zebra.png\n"," create mode 100644 input/Set14/LRbicx4/baboon.png\n"," create mode 100644 input/Set14/LRbicx4/barbara.png\n"," create mode 100644 input/Set14/LRbicx4/bridge.png\n"," create mode 100644 input/Set14/LRbicx4/coastguard.png\n"," create mode 100644 input/Set14/LRbicx4/comic.png\n"," create mode 100644 input/Set14/LRbicx4/face.png\n"," create mode 100644 input/Set14/LRbicx4/flowers.png\n"," create mode 100644 input/Set14/LRbicx4/foreman.png\n"," create mode 100644 input/Set14/LRbicx4/lenna.png\n"," create mode 100644 input/Set14/LRbicx4/man.png\n"," create mode 100644 input/Set14/LRbicx4/monarch.png\n"," create mode 100644 input/Set14/LRbicx4/pepper.png\n"," create mode 100644 input/Set14/LRbicx4/ppt3.png\n"," create mode 100644 input/Set14/LRbicx4/zebra.png\n"," create mode 100644 input/Set14/original/baboon.png\n"," create mode 100644 input/Set14/original/barbara.png\n"," create mode 100644 input/Set14/original/bridge.png\n"," create mode 100644 input/Set14/original/coastguard.png\n"," create mode 100644 input/Set14/original/comic.png\n"," create mode 100644 input/Set14/original/face.png\n"," create mode 100644 input/Set14/original/flowers.png\n"," create mode 100644 input/Set14/original/foreman.png\n"," create mode 100644 input/Set14/original/lenna.png\n"," create mode 100644 input/Set14/original/man.png\n"," create mode 100644 input/Set14/original/monarch.png\n"," create mode 100644 input/Set14/original/pepper.png\n"," create mode 100644 input/Set14/original/ppt3.png\n"," create mode 100644 input/Set14/original/zebra.png\n"," create mode 100644 input/Set5/GTmod12/baby.png\n"," create mode 100644 input/Set5/GTmod12/bird.png\n"," create mode 100644 input/Set5/GTmod12/butterfly.png\n"," create mode 100644 input/Set5/GTmod12/head.png\n"," create mode 100644 input/Set5/GTmod12/woman.png\n"," create mode 100644 input/Set5/LRbicx2/baby.png\n"," create mode 100644 input/Set5/LRbicx2/bird.png\n"," create mode 100644 input/Set5/LRbicx2/butterfly.png\n"," create mode 100644 input/Set5/LRbicx2/head.png\n"," create mode 100644 input/Set5/LRbicx2/woman.png\n"," create mode 100644 input/Set5/LRbicx3/baby.png\n"," create mode 100644 input/Set5/LRbicx3/bird.png\n"," create mode 100644 input/Set5/LRbicx3/butterfly.png\n"," create mode 100644 input/Set5/LRbicx3/head.png\n"," create mode 100644 input/Set5/LRbicx3/woman.png\n"," create mode 100644 input/Set5/LRbicx4/baby.png\n"," create mode 100644 input/Set5/LRbicx4/bird.png\n"," create mode 100644 input/Set5/LRbicx4/butterfly.png\n"," create mode 100644 input/Set5/LRbicx4/head.png\n"," create mode 100644 input/Set5/LRbicx4/woman.png\n"," create mode 100644 input/Set5/original/baby.png\n"," create mode 100644 input/Set5/original/bird.png\n"," create mode 100644 input/Set5/original/butterfly.png\n"," create mode 100644 input/Set5/original/head.png\n"," create mode 100644 input/Set5/original/woman.png\n"," create mode 100644 input/T91/t1.png\n"," create mode 100644 input/T91/t10.png\n"," create mode 100644 input/T91/t11.png\n"," create mode 100644 input/T91/t12.png\n"," create mode 100644 input/T91/t13.png\n"," create mode 100644 input/T91/t14.png\n"," create mode 100644 input/T91/t15.png\n"," create mode 100644 input/T91/t16.png\n"," create mode 100644 input/T91/t17.png\n"," create mode 100644 input/T91/t18.png\n"," create mode 100644 input/T91/t19.png\n"," create mode 100644 input/T91/t2.png\n"," create mode 100644 input/T91/t20.png\n"," create mode 100644 input/T91/t21.png\n"," create mode 100644 input/T91/t22.png\n"," create mode 100644 input/T91/t23.png\n"," create mode 100644 input/T91/t24.png\n"," create mode 100644 input/T91/t25.png\n"," create mode 100644 input/T91/t26.png\n"," create mode 100644 input/T91/t27.png\n"," create mode 100644 input/T91/t28.png\n"," create mode 100644 input/T91/t29.png\n"," create mode 100644 input/T91/t3.png\n"," create mode 100644 input/T91/t30.png\n"," create mode 100644 input/T91/t31.png\n"," create mode 100644 input/T91/t32.png\n"," create mode 100644 input/T91/t33.png\n"," create mode 100644 input/T91/t34.png\n"," create mode 100644 input/T91/t35.png\n"," create mode 100644 input/T91/t36.png\n"," create mode 100644 input/T91/t37.png\n"," create mode 100644 input/T91/t38.png\n"," create mode 100644 input/T91/t39.png\n"," create mode 100644 input/T91/t4.png\n"," create mode 100644 input/T91/t40.png\n"," create mode 100644 input/T91/t42.png\n"," create mode 100644 input/T91/t43.png\n"," create mode 100644 input/T91/t44.png\n"," create mode 100644 input/T91/t45.png\n"," create mode 100644 input/T91/t46.png\n"," create mode 100644 input/T91/t47.png\n"," create mode 100644 input/T91/t48.png\n"," create mode 100644 input/T91/t49.png\n"," create mode 100644 input/T91/t5.png\n"," create mode 100644 input/T91/t50.png\n"," create mode 100644 input/T91/t51.png\n"," create mode 100644 input/T91/t52.png\n"," create mode 100644 input/T91/t53.png\n"," create mode 100644 input/T91/t54.png\n"," create mode 100644 input/T91/t55.png\n"," create mode 100644 input/T91/t56.png\n"," create mode 100644 input/T91/t57.png\n"," create mode 100644 input/T91/t58.png\n"," create mode 100644 input/T91/t59.png\n"," create mode 100644 input/T91/t6.png\n"," create mode 100644 input/T91/t60.png\n"," create mode 100644 input/T91/t61.png\n"," create mode 100644 input/T91/t62.png\n"," create mode 100644 input/T91/t63.png\n"," create mode 100644 input/T91/t64.png\n"," create mode 100644 input/T91/t65.png\n"," create mode 100644 input/T91/t66.png\n"," create mode 100644 input/T91/t7.png\n"," create mode 100644 input/T91/t8.png\n"," create mode 100644 input/T91/t9.png\n"," create mode 100644 input/T91/tt1.png\n"," create mode 100644 input/T91/tt10.png\n"," create mode 100644 input/T91/tt12.png\n"," create mode 100644 input/T91/tt13.png\n"," create mode 100644 input/T91/tt14.png\n"," create mode 100644 input/T91/tt15.png\n"," create mode 100644 input/T91/tt16.png\n"," create mode 100644 input/T91/tt17.png\n"," create mode 100644 input/T91/tt18.png\n"," create mode 100644 input/T91/tt19.png\n"," create mode 100644 input/T91/tt2.png\n"," create mode 100644 input/T91/tt20.png\n"," create mode 100644 input/T91/tt21.png\n"," create mode 100644 input/T91/tt22.png\n"," create mode 100644 input/T91/tt23.png\n"," create mode 100644 input/T91/tt24.png\n"," create mode 100644 input/T91/tt25.png\n"," create mode 100644 input/T91/tt26.png\n"," create mode 100644 input/T91/tt27.png\n"," create mode 100644 input/T91/tt3.png\n"," create mode 100644 input/T91/tt4.png\n"," create mode 100644 input/T91/tt5.png\n"," create mode 100644 input/T91/tt6.png\n"," create mode 100644 input/T91/tt7.png\n"," create mode 100644 input/T91/tt8.png\n"," create mode 100644 input/T91/tt9.png\n"]}],"source":["!git pull"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1037,"status":"ok","timestamp":1728388879926,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"kgX9MTnv__xc","outputId":"24529da2-c3d3-4123-8022-ecabdfb1999f"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: not a git repository (or any of the parent directories): .git\n"]}],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4084,"status":"ok","timestamp":1728321821916,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"EXqwe0l9ABWA","outputId":"7f01249f-f40f-4a65-a21e-f30653f9cc89"},"outputs":[{"name":"stdout","output_type":"stream","text":["[main 1a17ac2] added connection for google colab\n"," 1 file changed, 1 insertion(+), 18 deletions(-)\n"," rewrite dl-superresolution.ipynb (100%)\n"]}],"source":["!git commit -a -m \"added connection for google colab\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3046,"status":"ok","timestamp":1728321831755,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"6j8uohs5AMSU","outputId":"2f87b872-9427-43b6-b139-98941dbeec53"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enumerating objects: 5, done.\n","Counting objects:  20% (1/5)\rCounting objects:  40% (2/5)\rCounting objects:  60% (3/5)\rCounting objects:  80% (4/5)\rCounting objects: 100% (5/5)\rCounting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  33% (1/3)\rCompressing objects:  66% (2/3)\rCompressing objects: 100% (3/3)\rCompressing objects: 100% (3/3), done.\n","Writing objects:  33% (1/3)\rWriting objects:  66% (2/3)\rWriting objects: 100% (3/3)\rWriting objects: 100% (3/3), 1.54 KiB | 197.00 KiB/s, done.\n","Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n","To https://github.com/Lollobin/dl-superresolution-ipynb\n","   f7c49f4..1a17ac2  main -> main\n"]}],"source":["!git push"]},{"cell_type":"markdown","metadata":{},"source":["# Preparation"]},{"cell_type":"markdown","metadata":{"id":"GjVWlSQm8TPi"},"source":["## Data Loading\n","\n","Currently all input images are included in the git repository."]},{"cell_type":"markdown","metadata":{"id":"df1rTJmG-dp-"},"source":["## Utils\n","\n","Define utility functions that are used later on."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"7hvJVv0i-o2P"},"outputs":[],"source":["import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from torchvision.utils import save_image\n","plt.style.use('ggplot')\n","def psnr(label, outputs, max_val=1.):\n","    \"\"\"\n","    Compute Peak Signal to Noise Ratio (the higher the better).\n","    PSNR = 20 * log10(MAXp) - 10 * log10(MSE).\n","    https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio#Definition\n","    Note that the output and label pixels (when dealing with images) should\n","    be normalized as the `max_val` here is 1 and not 255.\n","    \"\"\"\n","    label = label.cpu().detach().numpy()\n","    outputs = outputs.cpu().detach().numpy()\n","    diff = outputs - label\n","    rmse = math.sqrt(np.mean((diff) ** 2))\n","    if rmse == 0:\n","        return 100\n","    else:\n","        PSNR = 20 * math.log10(max_val / rmse)\n","        return PSNR\n","\n","def save_plot(train_loss, val_loss, train_psnr, val_psnr):\n","    # Loss plots.\n","    plt.figure(figsize=(10, 7))\n","    plt.plot(train_loss, color='orange', label='train loss')\n","    plt.plot(val_loss, color='red', label='validataion loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig('outputs/loss.png')\n","    plt.close()\n","    # PSNR plots.\n","    plt.figure(figsize=(10, 7))\n","    plt.plot(train_psnr, color='green', label='train PSNR dB')\n","    plt.plot(val_psnr, color='blue', label='validataion PSNR dB')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('PSNR (dB)')\n","    plt.legend()\n","    plt.savefig('outputs/psnr.png')\n","    plt.close()\n","\n","def save_model_state(model):\n","    # save the model to disk\n","    print('Saving model...')\n","    torch.save(model.state_dict(), 'outputs/model.pth')\n","\n","def save_model(epochs, model, optimizer, criterion):\n","    \"\"\"\n","    Function to save the trained model to disk.\n","    \"\"\"\n","    # Remove the last model checkpoint if present.\n","    torch.save({\n","                'epoch': epochs+1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': criterion,\n","                }, f\"outputs/model_ckpt.pth\")\n","\n","def save_validation_results(outputs, epoch, batch_iter):\n","    \"\"\"\n","    Function to save the validation reconstructed images.\n","    \"\"\"\n","    save_image(\n","        outputs,\n","        f\"outputs/valid_results/val_sr_{epoch}_{batch_iter}.png\"\n","    )"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import torch\n","import numpy as np\n","import glob as glob\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image\n","\n","TRAIN_BATCH_SIZE = 128\n","TEST_BATCH_SIZE = 1\n","\n","# The SRCNN dataset module.\n","class SRCNNDataset(Dataset):\n","    def __init__(self, image_paths, label_paths):\n","        self.all_image_paths = glob.glob(f\"{image_paths}/*\")\n","        self.all_label_paths = glob.glob(f\"{label_paths}/*\") \n","    \n","    def __len__(self):\n","        return (len(self.all_image_paths))\n","    \n","    def __getitem__(self, index):\n","        image = Image.open(self.all_image_paths[index]).convert('RGB')\n","        label = Image.open(self.all_label_paths[index]).convert('RGB')\n","        image = np.array(image, dtype=np.float32)\n","        label = np.array(label, dtype=np.float32)\n","        image /= 255.\n","        label /= 255.\n","        image = image.transpose([2, 0, 1])\n","        label = label.transpose([2, 0, 1])\n","        return (\n","            torch.tensor(image, dtype=torch.float),\n","            torch.tensor(label, dtype=torch.float)\n","        )\n","    \n","# Prepare the datasets.\n","def get_datasets(\n","    train_image_paths, train_label_paths,\n","    valid_image_path, valid_label_paths\n","):\n","    dataset_train = SRCNNDataset(\n","        train_image_paths, train_label_paths\n","    )\n","    dataset_valid = SRCNNDataset(\n","        valid_image_path, valid_label_paths\n","    )\n","    return dataset_train, dataset_valid\n","\n","# Prepare the data loaders\n","def get_dataloaders(dataset_train, dataset_valid):\n","    train_loader = DataLoader(\n","        dataset_train, \n","        batch_size=TRAIN_BATCH_SIZE,\n","        shuffle=True\n","    )\n","    valid_loader = DataLoader(\n","        dataset_valid, \n","        batch_size=TEST_BATCH_SIZE,\n","        shuffle=False\n","    )\n","    return train_loader, valid_loader"]},{"cell_type":"markdown","metadata":{"id":"ubzGejQl8rsD"},"source":["## Generate Patches"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"elapsed":468,"status":"error","timestamp":1728389383714,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"us157aRN8uAI","outputId":"5b9d886a-38f8-41ea-ee6d-abfca3ea538f"},"outputs":[],"source":["from PIL import Image\n","from tqdm import tqdm\n","\n","import matplotlib.pyplot as plt\n","import patchify\n","import numpy as np\n","import matplotlib.gridspec as gridspec\n","import glob as glob\n","import os\n","import cv2\n","\n","SHOW_PATCHES = False\n","STRIDE = 14\n","SIZE = 32\n","\n","def show_patches(patches):\n","    plt.figure(figsize=(patches.shape[0], patches.shape[1]))\n","    gs = gridspec.GridSpec(patches.shape[0], patches.shape[1])\n","    gs.update(wspace=0.01, hspace=0.02)\n","    counter = 0\n","    for i in range(patches.shape[0]):\n","        for j in range(patches.shape[1]):\n","            ax = plt.subplot(gs[counter])\n","            plt.imshow(patches[i, j, 0, :, :, :])\n","            plt.axis('off')\n","            counter += 1\n","    plt.show()\n","\n","def create_patches(\n","    input_paths, out_hr_path, out_lr_path,\n","):\n","    os.makedirs(out_hr_path, exist_ok=True)\n","    os.makedirs(out_lr_path, exist_ok=True)\n","    all_paths = []\n","    for input_path in input_paths:\n","        all_paths.extend(glob.glob(f\"{input_path}/*\"))\n","    print(f\"Creating patches for {len(all_paths)} images\")\n","    for image_path in tqdm(all_paths, total=len(all_paths)):\n","        image = Image.open(image_path)\n","        image_name = image_path.split(os.path.sep)[-1].split('.')[0]\n","        w, h = image.size\n","        # Create patches of size (32, 32, 3)\n","        patches = patchify.patchify(np.array(image), (32, 32, 3), STRIDE)\n","        if SHOW_PATCHES:\n","            show_patches(patches)\n","        counter = 0\n","        for i in range(patches.shape[0]):\n","            for j in range(patches.shape[1]):\n","                counter += 1\n","                patch = patches[i, j, 0, :, :, :]\n","                patch = cv2.cvtColor(patch, cv2.COLOR_RGB2BGR)\n","                cv2.imwrite(\n","                    f\"{out_hr_path}/{image_name}_{counter}.png\",\n","                    patch\n","                )\n","                # Convert to bicubic and save.\n","                h, w, _ = patch.shape\n","                low_res_img = cv2.resize(patch, (int(w*0.5), int(h*0.5)),\n","                                        interpolation=cv2.INTER_CUBIC)\n","                # Now upscale using BICUBIC.\n","                high_res_upscale = cv2.resize(low_res_img, (w, h),\n","                                            interpolation=cv2.INTER_CUBIC)\n","                cv2.imwrite(\n","                    f\"{out_lr_path}/{image_name}_{counter}.png\",\n","                    high_res_upscale\n","                )"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":1008,"status":"error","timestamp":1728388862964,"user":{"displayName":"Benno Kossatz","userId":"06085090293965508960"},"user_tz":-120},"id":"vHT7gnsN_UBt","outputId":"661f25b8-ee89-4da4-946c-59eaa8c11596"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating patches for 91 images\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 91/91 [00:18<00:00,  4.92it/s]\n"]}],"source":["create_patches(['input/T91'], 'input/t91_hr_patches', 'input/t91_lr_patches')"]},{"cell_type":"markdown","metadata":{},"source":["## Bicubic Scaling for Validation"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"zfGA9wyqAHH6"},"outputs":[{"name":"stdout","output_type":"stream","text":["19\n","Scaling factor: 0.5\n","Low resolution images save path: input/test_bicubic_rgb_2x\n","Original image dimensions: 500, 480\n","Original image dimensions: 720, 576\n","Original image dimensions: 512, 512\n","Original image dimensions: 352, 288\n","Original image dimensions: 250, 361\n","Original image dimensions: 276, 276\n","Original image dimensions: 500, 362\n","Original image dimensions: 352, 288\n","Original image dimensions: 512, 512\n","Original image dimensions: 512, 512\n","Original image dimensions: 768, 512\n","Original image dimensions: 512, 512\n","Original image dimensions: 529, 656\n","Original image dimensions: 586, 391\n","Original image dimensions: 512, 512\n","Original image dimensions: 288, 288\n","Original image dimensions: 256, 256\n","Original image dimensions: 280, 280\n","Original image dimensions: 228, 344\n"]}],"source":["from PIL import Image\n","import glob as glob\n","import os\n","\n","paths = ['input/Set14/original', 'input/Set5/original']\n","scale_factor = '2x' # options 2x, 3x, 4x\n","images = []\n","\n","for path in paths:\n","    images.extend(glob.glob(f\"{path}/*.png\"))\n","print(len(images))\n","# Select scaling-factor and set up directories according to that.\n","if scale_factor == '2x':\n","    scale_factor = 0.5\n","    os.makedirs('input/test_bicubic_rgb_2x', exist_ok=True)\n","    save_path_lr = 'input/test_bicubic_rgb_2x'\n","    os.makedirs('input/test_hr', exist_ok=True)\n","    save_path_hr = 'input/test_hr'\n","if scale_factor == '3x':\n","    scale_factor = 0.333\n","    os.makedirs('input/test_bicubic_rgb_3x', exist_ok=True)\n","    os.makedirs('input/test_hr', exist_ok=True)\n","    save_path_lr = 'input/test_bicubic_rgb_3x'\n","    save_path_hr = 'input/test_hr'\n","if scale_factor == '4x':\n","    scale_factor = 0.25\n","    os.makedirs('input/test_bicubic_rgb_4x', exist_ok=True)\n","    os.makedirs('input/test_hr', exist_ok=True)\n","    save_path_lr = 'input/test_bicubic_rgb_4x'\n","    save_path_hr = 'input/test_hr'\n","print(f\"Scaling factor: {scale_factor}\")\n","print(f\"Low resolution images save path: {save_path_lr}\")\n","for image in images:\n","    orig_img = Image.open(image)\n","    image_name = image.split(os.path.sep)[-1]\n","    w, h = orig_img.size[:]\n","    print(f\"Original image dimensions: {w}, {h}\")\n","    orig_img.save(f\"{save_path_hr}/{image_name}\")\n","    low_res_img = orig_img.resize((int(w*scale_factor), int(h*scale_factor)), Image.BICUBIC)\n","    # Upscale using BICUBIC.\n","    high_res_upscale = low_res_img.resize((w, h), Image.BICUBIC)\n","    high_res_upscale.save(f\"{save_path_lr}/{image_name}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Network Definition"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(\n","            3, 64, kernel_size=9, stride=(1, 1), padding=(2, 2)\n","        )\n","        self.conv2 = nn.Conv2d(\n","            64, 32, kernel_size=1, stride=(1, 1), padding=(2, 2)\n","        )\n","        self.conv3 = nn.Conv2d(\n","            32, 3, kernel_size=5, stride=(1, 1), padding=(2, 2)\n","        )\n","    \n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = self.conv3(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import time\n","import torch.optim as optim\n","import torch.nn as nn\n","import os\n","from tqdm import tqdm\n","\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Computation device:  cuda\n","SRCNN(\n","  (conv1): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(2, 2))\n","  (conv2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n","  (conv3): Conv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",")\n","Training samples: 22227\n","Validation samples: 19\n","Epoch 1 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [05:16<00:00,  1.82s/it]\n","100%|██████████| 19/19 [00:01<00:00, 18.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 18.525\n","Val PSNR: 24.986\n","Saving model...\n","Epoch 2 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:25<00:00,  6.94it/s]\n","100%|██████████| 19/19 [00:00<00:00, 36.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 22.547\n","Val PSNR: 26.482\n","Saving model...\n","Epoch 3 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:19<00:00,  9.01it/s]\n","100%|██████████| 19/19 [00:00<00:00, 31.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 24.251\n","Val PSNR: 26.967\n","Saving model...\n","Epoch 4 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:19<00:00,  9.12it/s]\n","100%|██████████| 19/19 [00:00<00:00, 31.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 25.188\n","Val PSNR: 26.953\n","Saving model...\n","Epoch 5 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:19<00:00,  8.91it/s]\n","100%|██████████| 19/19 [00:00<00:00, 39.74it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 25.817\n","Val PSNR: 27.776\n","Saving model...\n","Epoch 6 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:18<00:00,  9.28it/s]\n","100%|██████████| 19/19 [00:00<00:00, 30.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 26.138\n","Val PSNR: 27.819\n","Saving model...\n","Epoch 7 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:18<00:00,  9.20it/s]\n","100%|██████████| 19/19 [00:00<00:00, 34.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 26.447\n","Val PSNR: 28.096\n","Saving model...\n","Epoch 8 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:19<00:00,  9.09it/s]\n","100%|██████████| 19/19 [00:00<00:00, 39.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 26.643\n","Val PSNR: 27.688\n","Saving model...\n","Epoch 9 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:18<00:00,  9.28it/s]\n","100%|██████████| 19/19 [00:00<00:00, 39.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 26.786\n","Val PSNR: 28.132\n","Saving model...\n","Epoch 10 of 10\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:19<00:00,  9.10it/s]\n","100%|██████████| 19/19 [00:00<00:00, 31.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train PSNR: 27.087\n","Val PSNR: 28.473\n","Saving model...\n","Finished training in: 8.371 minutes\n"]}],"source":["# Learning parameters.\n","epochs = 10 # Number of epochs to train the SRCNN model for.\n","lr = 0.001 # Learning rate.\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","weights = None # weights/checkpoint path to resume training\n","\n","# Constants\n","TRAIN_LABEL_PATHS = 'input/t91_hr_patches'\n","TRAN_IMAGE_PATHS = 'input/t91_lr_patches'\n","VALID_LABEL_PATHS = 'input/test_hr'\n","VALID_IMAGE_PATHS = 'input/test_bicubic_rgb_2x'\n","SAVE_VALIDATION_RESULTS = True\n","\n","os.makedirs('outputs/valid_results', exist_ok=True)\n","\n","# Initialize the model.\n","print('Computation device: ', device)\n","model = SRCNN().to(device)\n","if weights is not None:\n","    print('Loading weights to resume training...')\n","    checkpoint = torch.load(weights)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","print(model)\n","\n","# Optimizer.\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","# Loss function. \n","criterion = nn.MSELoss()\n","\n","dataset_train, dataset_valid = get_datasets(\n","    TRAN_IMAGE_PATHS, TRAIN_LABEL_PATHS,\n","    VALID_IMAGE_PATHS, VALID_LABEL_PATHS\n",")\n","train_loader, valid_loader = get_dataloaders(dataset_train, dataset_valid)\n","\n","print(f\"Training samples: {len(dataset_train)}\")\n","print(f\"Validation samples: {len(dataset_valid)}\")\n","\n","def train(model, dataloader):\n","    model.train()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    for bi, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n","        image_data = data[0].to(device)\n","        label = data[1].to(device)\n","        \n","        # Zero grad the optimizer.\n","        optimizer.zero_grad()\n","        outputs = model(image_data)\n","        loss = criterion(outputs, label)\n","        \n","        # Backpropagation.\n","        loss.backward()\n","        # Update the parameters.\n","        optimizer.step()\n","        \n","        # Add loss of each item (total items in a batch = batch size).\n","        running_loss += loss.item()\n","        # Calculate batch psnr (once every `batch_size` iterations).\n","        batch_psnr =  psnr(label, outputs)\n","        running_psnr += batch_psnr\n","    \n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/len(dataloader)\n","    return final_loss, final_psnr\n","\n","def validate(model, dataloader, epoch):\n","    model.eval()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    with torch.no_grad():\n","        for bi, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n","            image_data = data[0].to(device)\n","            label = data[1].to(device)\n","            \n","            outputs = model(image_data)\n","            loss = criterion(outputs, label)\n","            \n","            # Add loss of each item (total items in a batch = batch size) .\n","            running_loss += loss.item()\n","            \n","            # Calculate batch psnr (once every `batch_size` iterations).\n","            batch_psnr = psnr(label, outputs)\n","            running_psnr += batch_psnr\n","            \n","            # For saving the batch samples for the validation results\n","            # every 500 epochs.\n","            if SAVE_VALIDATION_RESULTS and (epoch % 500) == 0:\n","                save_validation_results(outputs, epoch, bi)\n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/len(dataloader)\n","    return final_loss, final_psnr\n","\n","train_loss, val_loss = [], []\n","train_psnr, val_psnr = [], []\n","start = time.time()\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch + 1} of {epochs}\")\n","    train_epoch_loss, train_epoch_psnr = train(model, train_loader)\n","    val_epoch_loss, val_epoch_psnr = validate(model, valid_loader, epoch+1)\n","    print(f\"Train PSNR: {train_epoch_psnr:.3f}\")\n","    print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n","    train_loss.append(train_epoch_loss)\n","    train_psnr.append(train_epoch_psnr)\n","    val_loss.append(val_epoch_loss)\n","    val_psnr.append(val_epoch_psnr)\n","    \n","    # Save model with all information every 100 epochs. Can be used \n","    # resuming training.\n","    if (epoch+1) % 100 == 0:\n","        save_model(epoch, model, optimizer, criterion)\n","    \n","    # Save the model state dictionary only every epoch. Small size, \n","    # can be used for inference.\n","    save_model_state(model)\n","    \n","    # Save the PSNR and loss plots every epoch.\n","    save_plot(train_loss, val_loss, train_psnr, val_psnr)\n","end = time.time()\n","print(f\"Finished training in: {((end-start)/60):.3f} minutes\") "]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import torch\n","import glob as glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def validate(model, dataloader, device):\n","    model.eval()\n","    running_loss = 0.0\n","    running_psnr = 0.0\n","    with torch.no_grad():\n","        for bi, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n","            image_data = data[0].to(device)\n","            label = data[1].to(device)\n","            outputs = model(image_data)\n","            # Calculate batch psnr (once every `batch_size` iterations).\n","            batch_psnr = psnr(label, outputs)\n","            running_psnr += batch_psnr\n","\n","    final_loss = running_loss/len(dataloader.dataset)\n","    final_psnr = running_psnr/len(dataloader)\n","    return final_loss, final_psnr\n","\n","# The SRCNN dataset module.\n","class SRCNNDataset(Dataset):\n","    def __init__(self, image_paths):\n","        self.all_image_paths = glob.glob(f\"{image_paths}/*\")\n","\n","    def __len__(self):\n","        return (len(self.all_image_paths))\n","\n","    def __getitem__(self, index):\n","        # The high resolution ground truth label.\n","        label = Image.open(self.all_image_paths[index]).convert('RGB')\n","        w, h = label.size[:]\n","        # Convert to 2x bicubic.\n","        low_res_img = label.resize((int(w*0.5), int(h*0.5)), Image.BICUBIC)\n","        # The low resolution input image.\n","        image = low_res_img.resize((w, h), Image.BICUBIC)\n","\n","        # Uncomment the below code to visualize the image for sanity check.\n","        #plt.figure(figsize=(12, 9))\n","        #plt.subplot(1, 2, 1)\n","        #plt.imshow(image)\n","        #plt.axis('off')\n","        #plt.subplot(1, 2, 2)\n","        #plt.imshow(label)\n","        #plt.axis('off')\n","        #plt.show()\n","\n","        image = np.array(image, dtype=np.float32)\n","        label = np.array(label, dtype=np.float32)\n","\n","        image /= 255.\n","        label /= 255.\n","\n","        image = image.transpose([2, 0, 1])\n","        label = label.transpose([2, 0, 1])\n","\n","        return (\n","            torch.tensor(image, dtype=torch.float),\n","            torch.tensor(label, dtype=torch.float)\n","        )\n","\n","# Prepare the datasets.\n","def get_datasets(\n","    image_paths\n","):\n","    dataset_test = SRCNNDataset(image_paths)\n","    return dataset_test\n","\n","# Prepare the data loaders\n","def get_dataloaders(dataset_test):\n","    test_loader = DataLoader(\n","        dataset_test, \n","        batch_size=1,\n","        shuffle=False\n","    )\n","    return test_loader"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\bkoss\\AppData\\Local\\Temp\\ipykernel_6292\\1485427371.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('outputs/model.pth'))\n","100%|██████████| 5/5 [00:00<00:00, 18.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test PSNR on Set5: 30.782\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14/14 [00:00<00:00, 39.99it/s]"]},{"name":"stdout","output_type":"stream","text":["Test PSNR on Set14: 27.649\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Load the model.\n","model = SRCNN().to(device)\n","model.load_state_dict(torch.load('outputs/model.pth'))\n","data_paths = [\n","    ['input/Set5/original', 'Set5'],\n","    ['input/Set14/original', 'Set14']\n","]\n","for data_path in data_paths:\n","    dataset_test = get_datasets(data_path[0])\n","    test_loader = get_dataloaders(dataset_test)\n","    _, test_psnr = validate(model, test_loader, device)\n","    print(f\"Test PSNR on {data_path[1]}: {test_psnr:.3f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
